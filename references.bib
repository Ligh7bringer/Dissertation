@article{Manning2014,
	abstract = {We describe the design and use of the Stanford CoreNLP toolkit, an extensible pipeline that provides core natural language analysis. This toolkit is quite widely used, both in the research NLP community and also among commercial and government users of open source NLP technology. We suggest that this follows from a simple, approachable design, straightforward interfaces, the inclusion of robust and good quality analysis components, and not requiring use of a large amount of associated baggage.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1011.1669v3},
	author = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and McClosky, David},
	doi = {10.3115/v1/P14-5010},
	eprint = {arXiv:1011.1669v3},
	isbn = {9781941643006},
	issn = {1098-6596},
	journal = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
	pages = {55--60},
	pmid = {25246403},
	title = {{The Stanford CoreNLP Natural Language Processing Toolkit}},
	url = {http://aclweb.org/anthology/P14-5010},
	year = {2014}
}

@article{Bhagwat2018,
	author = {Bhagwat, Vyas Ajay},
	journal = {Master's Projects},
	title = {{Deep Learning for Chatbots}},
	url = {http://www.wildml.com/2016/04/deep-learning-for-chatbots-part-1-introduction/},
	year = {2018}
}

@article{Hill2015,
	abstract = {This study analyzed how communication changes when people communicate with an intelligent agent as opposed to with another human. We compared 100 instant messaging conversations to 100 exchanges with the popular chatbot Cleverbot along seven dimensions: words per message, words per conversation, messages per conversation, word uniqueness, and use of profanity, shorthand, and emoticons. A MANOVA indicated that people communicated with the chatbot for longer durations (but with shorter messages) than they did with another human. Additionally, human-chatbot communication lacked much of the richness of vocabulary found in conversations among people, and exhibited greater profanity. These results suggest that while human language skills transfer easily to human-chatbot communication, there are notable differences in the content and quality of such conversations.},
	author = {Hill, Jennifer and {Randolph Ford}, W. and Farreras, Ingrid G.},
	doi = {10.1016/j.chb.2015.02.026},
	issn = {07475632},
	journal = {Computers in Human Behavior},
	keywords = {CMC,Chatbot,Cleverbot,IM,Instant messaging},
	pages = {245--250},
	publisher = {Elsevier Ltd},
	title = {{Real conversations with artificial intelligence: A comparison between human-human online conversations and human-chatbot conversations}},
	url = {http://dx.doi.org/10.1016/j.chb.2015.02.026},
	volume = {49},
	year = {2015}
}

@article{Socher2017,
	abstract = {Keyphrases: Natural Language Processing. Word Vectors. Singu-lar Value Decomposition. Skip-gram. Continuous Bag of Words (CBOW). Negative Sampling. Hierarchical Softmax. Word2Vec. This set of notes begins by introducing the concept of Natural Language Processing (NLP) and the problems NLP faces today. We then move forward to discuss the concept of representing words as numeric vectors. Lastly, we discuss popular approaches to designing word vectors.},
	author = {Socher, Richard and Genthial, Guillaume and Socher, Richard},
	keywords = {search},
	pages = {1--14},
	title = {{CS 224 n : Natural Language Processing with Deep Lecture Notes : Part I}},
	year = {2017}
}

@article{Martinez2010,
	abstract = {Approximately 40 years ago, the goal of endowing computers with the capacity to understand natural language began. These efforts were originally called natural language understanding, which is now more frequently called natural language processing (NLP). NLP is considered a branch of artificial intelligence (AI), but over the years it has become an interesting area of study in computational statistics and text data mining. NLP encompasses approaches that use computers to analyze, determine semantic similarity, and translate between languages. The area usually deals with written languages, but it could also be applied to speech. In this article, we cover definitions and concepts necessary for the understanding of NLP, methods at the word and sentence level (word sense disambiguation, part-of-speech tagging, and parsing), and the vector space model for NLP at the document level. Copyright {\textcopyright} 2010 John Wiley {\&} Sons, Inc.For further resources related to this article, please visit the WIREs website.},
	author = {Martinez, Angel R.},
	doi = {10.1002/wics.76},
	issn = {19395108},
	journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
	keywords = {disambiguation,information retrieval,latent semantic indexing,parsing,probabilistic grammars,word sense},
	number = {3},
	pages = {352--357},
	title = {{Natural language processing}},
	volume = {2},
	year = {2010}
}

@article{Yan2016,
	abstract = {Chatbots are emerging as the newest platform used by millions of consumers worldwide due in part to the commoditization of natural language services, which provide provide developers with many building blocks to create chatbots inexpensively. However, it is still difficult to build and deploy chatbots. Developers need to handle the coordination of the cognitive services to build the chatbot interface, integrate the chatbot with external services, and worry about extensibility, scalability, and maintenance. In this work, we present the architecture and prototype of a chatbot using a serverless platform, where developers compose stateless functions together to perform useful actions. We describe our serverless architecture based on function sequences, and how we used these functions to coordinate the cognitive microservices in the Watson Developer Cloud to allow the chatbot to interact with external services. The serverless model improves the extensibility of our chatbot, which currently supports 6 abilities: location based weather reports, jokes, date, reminders, and a simple music tutor.},
	author = {Yan, Mengting and Castro, Paul and Cheng, Perry and Ishakian, Vatche},
	doi = {10.1145/3007203.3007217},
	isbn = {9781450346696},
	journal = {Proceedings of the 1st International Workshop on Mashups of Things and APIs - MOTA '16},
	keywords = {bots,cloud computing,faas,serverless},
	pages = {1--4},
	title = {{Building a Chatbot with Serverless Computing}},
	url = {http://dl.acm.org/citation.cfm?doid=3007203.3007217},
	year = {2016}
}

@article{Mikkonen2018,
	author = {Mikkonen, Tommi},
	doi = {10.1007/978-3-319-74433-9},
	isbn = {978-3-319-74432-2},
	keywords = {aws,aws lambda,chatbot,facebook messenger,internet bot,microservices,serverless computing},
	pages = {75--86},
	title = {{Current Trends in Web Engineering}},
	url = {http://link.springer.com/10.1007/978-3-319-74433-9},
	volume = {10544},
	year = {2018}
}

@article{Young2017,
	abstract = {Deep learning methods employ multiple processing layers to learn hierarchical representations of data and have produced state-of-the-art results in many domains. Recently, a variety of model designs and methods have blossomed in the context of natural language processing (NLP). In this paper, we review significant deep learning related models and methods that have been employed for numerous NLP tasks and provide a walk-through of their evolution. We also summarize, compare and contrast the various models and put forward a detailed understanding of the past, present and future of deep learning in NLP.},
	archivePrefix = {arXiv},
	arxivId = {1708.02709},
	author = {Young, Tom and Hazarika, Devamanyu and Poria, Soujanya and Cambria, Erik},
	doi = {arXiv:1708.02709v6},
	eprint = {1708.02709},
	issn = {1556-603X VO  - 13},
	journal = {IEEE Computational Intelligence Magazine},
	keywords = {ek laboratories,nanyang technological university},
	number = {July},
	pages = {55--75},
	publisher = {IEEE},
	title = {{Recent Trends in Deep Learning Based Natural Language Processing}},
	url = {http://arxiv.org/abs/1708.02709},
	volume = {13},
	year = {2017}
}

@article{Jia2009,
	abstract = {CSIEC (Computer Simulation in Educational Communication) system with newly developed multiple functions for English instruction still focuses on supplying a virtual chatting partner (chatbot), which can chat in English with the English learners anytime anywhere. It generates communicative response according to the user input, the dialogue context, the user's and its own personality knowledge, common sense knowledge, and inference knowledge. All these kinds of knowledge are expressed in the form of NLML, an annotation language for natural language text. These NLMLs can either be automatically obtained through parsing the text, or be easily authored with the help of GUI editors designed by us. So the CSIEC system suggests a na{\"{i}}ve approach of logical reasoning and inference directly through syntactical and semantic analysis of textual knowledge. This approach has advantages over the old ELIZA-like keywords matching mechanism. The chatting log summarization of free Internet usage within six months demonstrates this advantage. In this paper, we present the system architecture and underlying technologies, and the educational application results. {\textcopyright} 2009 Elsevier B.V. All rights reserved.},
	author = {Jia, Jiyou},
	doi = {10.1016/j.knosys.2008.09.001},
	isbn = {0950-7051},
	issn = {09507051},
	journal = {Knowledge-Based Systems},
	keywords = {Chatbot,Computer assisted language learning,Human-computer interaction,Inference,Natural language processing},
	number = {4},
	pages = {249--255},
	publisher = {Elsevier B.V.},
	title = {{CSIEC: A computer assisted English learning chatbot based on textual knowledge and reasoning}},
	url = {http://dx.doi.org/10.1016/j.knosys.2008.09.001},
	volume = {22},
	year = {2009}
}

@article{Goldberg2015,
	abstract = {Over the past few years, neural networks have re-emerged as powerful machine-learning models, yielding state-of-the-art results in elds such as image recognition and speech processing. More recently, neural network models started to be applied also to textual natural language signals, again with very promising results. This tutorial surveys neural network models from the perspective of natural language processing research, in an attempt to bring natural-language researchers up to speed with the neural techniques. The tutorial covers input encoding for natural language tasks, feed-forward networks, convolutional networks, recurrent networks and recursive networks, as well as the computation graph abstraction for automatic gradient computation.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1510.00726v1},
	author = {Goldberg, Yoav},
	doi = {10.1613/jair.4992},
	eprint = {arXiv:1510.00726v1},
	issn = {1076-9757},
	journal = {Report},
	keywords = {Deep Learning,Neural Network},
	pages = {1--75},
	title = {{A Primer on Neural Network Models for Natural Language Processing}},
	volume = {57},
	year = {2015}
}

@article{Pereira2018,
	abstract = {{\textcopyright} 2018 ACM. This work introduces a set of quality attributes for chatbots. The selection is grounded on scholarly but also reputed blog references from 2016 and 2017. In addition, attributes should be amenable to be extracted (semi) automatically. On these premises, we consider four attributes: "support of a minimal set of common commands", "foresee language variations in both inputs and ouput", "human-assistance provision" and "timeliness". These attributes are worked out for the 100 most popular chatbots in Facebook Messager. The aim is to look for correlations between these attributes and chatbot popularity in terms of number of "likes". Results show that there is no significance correlation with any of the attributes. However, the experiment come up with two main insights. First, the lack of common communication paterns that would permit users to move their experiences and expectations from one chatbot to another. Second, the existence of many programming errors that reflect that bot programming is still a nascent area.},
	author = {Pereira, J. and D{\'{i}}az, O.},
	doi = {10.1145/3167132.3167362},
	isbn = {9781450351911},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {2144--2150},
	title = {{A quality analysis of facebook messenger's most popular chatbots}},
	volume = {Part F1378},
	year = {2018}
}

@article{Khatua2017,
	abstract = {{\textcopyright} 2017 IEEE. Data scientists are exploring various semi-supervised learning methods to build conversational agents - commonly known as chatterbot. This paper investigates various issues related to a political chatterbot where human agents are politically opinionated. Here, understanding the latent intent of human agent is crucial for developing an efficient political chatterbot. We set our study in the context of 2016 Brexit referendum. We argue that employing a subjectivity detector and an emotion analyzer, in addition to the keyword based topic detector, enhances the intent detection process. Next, we discuss the importance of maintaining political neutrality. To maintain its neutrality, a chatterbot needs to disassociate itself from a politically opinionated response. This can be achieved by associating a response with a user or a set of users. Nowadays, the Twitter platform provides an enormous amount of user-generated contents for various socio-economic events. Hence, we have considered tweet feeds for developing the overall chatterbot architecture in the political domain.},
	author = {Khatua, Aparup and Cambria, Erik and Khatua, Apalak and Chaturvedi, Iti},
	doi = {10.1109/ICDMW.2017.57},
	isbn = {9781538614808},
	issn = {23759259},
	journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
	keywords = {2016 Brexit Referendum,Chatterbot,Twitter},
	pages = {393--398},
	title = {{Let's Chat about Brexit! A Politically-Sensitive Dialog System Based on Twitter Data}},
	volume = {2017-Novem},
	year = {2017}
}

@article{Gardner2017,
	abstract = {This paper describes AllenNLP, a platform for research on deep learning methods in natural language understanding. AllenNLP is designed to support researchers who want to build novel language understanding models quickly and easily. It is built on top of PyTorch, allowing for dynamic computation graphs, and provides (1) a flexible data API that handles intelligent batching and padding, (2) high-level abstractions for common operations in working with text, and (3) a modular and extensible experiment framework that makes doing good science easy. It also includes reference implementations of high quality approaches for both core semantic problems (e.g. semantic role labeling (Palmer et al., 2005)) and language understanding applications (e.g. machine comprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source effort maintained by engineers and researchers at the Allen Institute for Artificial Intelligence.},
	archivePrefix = {arXiv},
	arxivId = {1803.07640},
	author = {Gardner, Matt and Grus, Joel and Neumann, Mark and Tafjord, Oyvind and Dasigi, Pradeep and Liu, Nelson and Peters, Matthew and Schmitz, Michael and Zettlemoyer, Luke},
	eprint = {1803.07640},
	pages = {3--8},
	title = {{AllenNLP: A Deep Semantic Natural Language Processing Platform}},
	url = {http://arxiv.org/abs/1803.07640},
	year = {2018}
}

@article{Shawar2005,
	abstract = {{\textless}p{\textgreater}A chatbot is a machine conversation system which interacts with human users via natural conversational language. Software to machine-learn conversational patterns from a transcribed dialogue corpus has been used to generate a range of chatbots speaking various languages and sublanguages including varieties of English, as well as French, Arabic and Afrikaans. This paper presents a program to learn from spoken transcripts of the Dialogue Diversity Corpus of English, the Minnesota French Corpus, the Corpus of Spoken Afrikaans, the Qur'an Arabic-English parallel corpus, and the British National Corpus of English; we discuss the problems which arose during learning and testing. Two main goals were achieved from the automation process. One was the ability to generate different versions of the chatbot in different languages, bringing chatbot technology to languages with few if any NLP resources: the corpus-based learning techniques transferred straightforwardly to develop chatbots for Afrikaans and Qur'anic Arabic. The second achievement was the ability to learn a very large number of categories within a short time, saving effort and errors in doing such work manually: we generated more than one million AIML categories or conversation-rules from the BNC corpus, 20 times the size of existing AIML rule-sets, and probably the biggest AI Knowledge-Base ever.{\textless}/p{\textgreater}},
	author = {Shawar, Bayan Abu and Atwell, Eric Steven},
	doi = {10.1075/ijcl.10.4.06sha},
	isbn = {00390526},
	issn = {1384-6655},
	journal = {International Journal of Corpus Linguistics},
	keywords = {afrikaans,aiml,an,arabic,artificial intelligence,british national corpus,chatbot,chatbot, dialogue, AIML, Artificial Intelligence,,dialogue,french,learning,lemmatised and unlemmatised lists,machine,qur},
	number = {4},
	pages = {489--516},
	pmid = {10501650},
	title = {{Using corpora in machine-learning chatbot systems}},
	url = {http://www.jbe-platform.com/content/journals/10.1075/ijcl.10.4.06sha},
	volume = {10},
	year = {2005}
}

@book{Poole:1997:CIL:275594,
	author = {Poole, David and Mackworth, Alan and Goebel, Randy},
	title = {Computational Intelligence: A Logical Approach},
	year = {1997},
	isbn = {0-19-510270-3},
	publisher = {Oxford University Press, Inc.},
	address = {New York, NY, USA}
}

@book{RusselStuart,
	author = {Russell, Stuart and Norvig, Peter},
	title = {Artificial Intelligence: A Modern Approach},
	year = {2009},
	edition = {3},
	publisher = {Prentice Hall Press},
	address = {Upper Saddle River, NJ, USA},
} 

@inproceedings{williams1983brief,
	title={{A Brief Introduction to Artificial Intelligence}},
	author={Williams, Chuck},
	booktitle={OCEANS'83, Proceedings},
	pages={94--99},
	year={1983},
	organization={IEEE}
}

@article{Khurana2017,
	author = {Khurana, Diksha and Koli, Aditya and Khatter, Kiran and Singh, Sukhdev},
	year = {2017},
	month = {8},
	pages = {},
	title = {{Natural Language Processing: State of The Art, Current Trends and Challenges}}
}

@article{Turing1950,
	author = {Turing, A. M.},
	title = {Computing machinery and intelligence},
	journal = {Mind},
	volume = {LIX},
	number = {236},
	pages = {433-460},
	year = {1950},
	doi = {10.1093/mind/LIX.236.433},
	URL = {http://dx.doi.org/10.1093/mind/LIX.236.433},
	eprint = {/oup/backfile/content_public/journal/mind/lix/236/10.1093_mind_lix.236.433/1/433.pdf}
}

@article{Lecun2015,
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	archivePrefix = {arXiv},
	arxivId = {arXiv:1312.6184v5},
	author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	doi = {10.1038/nature14539},
	eprint = {arXiv:1312.6184v5},
	isbn = {9780521835688},
	issn = {14764687},
	journal = {Nature},
	number = {7553},
	pages = {436--444},
	pmid = {10463930},
	title = {{Deep learning}},
	volume = {521},
	year = {2015}
}

@article{Searle1980,
	author = {Searle, John R},
	doi = {10.1017/S0140525X00005756},
	isbn = {0-262-02593-0},
	issn = {0140-525X, 1469-1825},
	journal = {Behavioral and Brain Sciences},
	number = {03},
	pages = {417},
	title = {{Minds, brains, and programs}},
	url = {http://www.journals.cambridge.org/abstract{\_}S0140525X00005756},
	volume = {3},
	year = {1980}
}

@article{Mauldin1994,
	author = {{Michael L. Mauldin}},
	isbn = {0-262-61102-3},
	journal = {Aaai},
	number = {4},
	pages = {254},
	title = {{Chatterbots, TinyMuds, and the Turing test: Entering the Loebner Prize competition}},
	year = {1994}
}

@article{Raine2009,
	author = {Raine2009},
	doi = {10.1109/ICICISYS.2009.5358137},
	isbn = {9781424447541},
	journal = {Proceedings - 2009 IEEE International Conference on Intelligent Computing and Intelligent Systems, ICIS 2009},
	keywords = {Cognitive load in communication,Dialogue,Discourse,Human speech understanding,Joint costs,Perspective-taking in communication,Speech dialogue systems},
	pages = {398--402},
	title = {{Making a clever intelligent agent: The theory behind the implementation}},
	volume = {3},
	year = {2009}
}

@incollection{Wallace2009,
	abstract = {This paper},
	author = {Wallace, Richard S.},
	booktitle = {Parsing the Turing Test: Philosophical and Methodological Issues in the Quest for the Thinking Computer},
	doi = {10.1007/978-1-4020-6710-5_13},
	isbn = {9781402067105},
	title = {{The anatomy of A.L.I.C.E.}},
	year = {2009}
}

@Online{SmarterChild:online,
	author = {Matt Carbone},
	title = {{Remembering SmarterChild}},
	url = {https://blog.talla.com/remembering-smarterchild},
	month = {12},
	year = {2016},
	urldate = {2018-11-12}
}

@Online{futurism:online,
	author = {Futurism},
	title = {The History of Chatbots},
	url = {https://futurism.com/images/the-history-of-chatbots-infographic/},
	month = {11},
	year = {2016},
	urldate = {2018-11-12}
}

@Online{Microsof8:online,
	author = {Rob Price},
	title = {{Microsoft deletes racist, genocidal tweets from AI chatbot Tay}},
	url = {http://uk.businessinsider.com/microsoft-deletes-racist-genocidal-tweets-from-ai-chatbot-tay-2016-3?r=US&IR=T},
	month = {3},
	year = {2016},
	urldate = {2018-11-12}
}

@Online{Taytweet55:online,
	author = {Andrew Griffin},
	title = {Tay tweets: Microsoft creates bizarre Twitter robot for people to chat to},
	url = {https://www.independent.co.uk/life-style/gadgets-and-tech/news/tay-tweets-microsoft-creates-bizarre-twitter-robot-for-people-to-chat-to-a6947806.html},
	month = {3},
	year = {2016},
	urldate = {2018-11-12}
}

@article{Floridi2009,
	abstract = {{An evaluation of the 2008 Loebner contest.}},
	author = {Floridi, Luciano and Taddeo, Mariarosaria and Turilli, Matteo},
	doi = {10.1007/s11023-008-9130-6},
	journal = {Minds and Machines},
	keywords = {AI,Loebner contest,Turing test},
	number = {1},
	pages = {145--150},
	title = {{Turing's imitation game: Still an impossible challenge for all machines and some judges - An evaluation of the 2008 loebner contest}},
	volume = {19},
	year = {2009}
}

@article{Porter1980,
	author = {M.F. Porter},
	title = {An algorithm for suffix stripping},
	journal = {Program},
	volume = {14},
	number = {3},
	pages = {130-137},
	year = {1980},
	doi = {10.1108/eb046814},
	
	URL = { 
	https://doi.org/10.1108/eb046814
	},
	eprint = { 
	https://doi.org/10.1108/eb046814
	},
	abstract = { The automatic removal of suffixes from words in English is of particular interest in the field of information retrieval. An algorithm for suffix stripping is described, which has been implemented as a short, fast program in BCPL. Although simple, it performs slightly better than a much more elaborate system with which it has been compared. It effectively works by treating complex suffixes as compounds made up of simple suffixes, and removing the simple suffixes in a number of steps. In each step the removal of the suffix is made to depend upon the form of the remaining stem, which usually involves a measure of its syllable length. }
}

@Online{Chatterbot:online,
	author = {{Gunther Cox}},
	title = {{ChatterBot 1.0.2 documentation}},
	url = {https://chatterbot.readthedocs.io/en/stable/},
	month = {1},
	year = {2019},
	urldate = {2018-10-02}
}

@Online{PyPI:online,
	author = {{The Python Software Foundation}},
	title = {{PyPI â€“ the Python Package Index}},
	url = {https://pypi.org/},
	year = {2019},
	note = {2019-02-23}
}

@article{Weizenbaum:1966,
	author = {Weizenbaum, Joseph},
	title = {{ELIZA---a Computer Program for the Study of Natural Language Communication Between Man and Machine}},
	journal = {Commun. ACM},
	issue_date = {Jan. 1966},
	volume = {9},
	number = {1},
	month = {1},
	year = {1966},
	issn = {0001-0782},
	pages = {36--45},
	numpages = {10},
	url = {http://doi.acm.org/10.1145/365153.365168},
	doi = {10.1145/365153.365168},
	acmid = {365168},
	publisher = {ACM},
	address = {New York, NY, USA}
}

@Online{jabberwacky:online,
	author = {Carpenter, R.},
	title = {{Jabberwacky.com}},
	url = {http://www.jabberwacky.com/},
	month = {},
	year = {1997},
	urldate = {2018-10-26}
}

@Online{cppfaq:online,
	author = {{Standard CPP Foundation}},
	title = {{ISO C++}},
	url = {https://isocpp.org/wiki/faq/},
	month = {},
	year = {2019},
	urldate = {2019-03-18}
}

@article{atwell:1987,
	author = {Atwell, Eric and Cliff, Dave},
	year = {1987},
	month = {1},
	pages = {49-51},
	title = {{Leeds Unix Knowledge Expert: a domain-dependent Expert System generated with domain-independent tools}},
	volume = {19},
	journal = {BCS-SGES: Journal of the British Computer Society Specialist Group on Expert Systems}
}

@article{Wilensky:1988,
	author = {Wilensky, Robert and Chin, David N. and Luria, Marc and Martin, James and Mayfield, James and Wu, Dekai},
	title = {{The Berkeley UNIX Consultant Project}},
	journal = {Comput. Linguist.},
	issue_date = {December 1988},
	volume = {14},
	number = {4},
	month = {12},
	year = {1988},
	issn = {0891-2017},
	pages = {35--84},
	numpages = {50},
	acmid = {65123},
	publisher = {MIT Press},
	address = {Cambridge, MA, USA}
}

@Online{loebner:online,
	author = {Loebner.net},
	title = {{What is the Loebner Prize?}},
	url = {https://web.archive.org/web/20170330123946/http:/www.loebner.net/Prizef/loebner-prize.html},
	month = {},
	year = {2017},
	urldate = {2018-10-15}
}

@misc{Kotsiantis2007,
	abstract = {Supervised machine learning is the search for algorithms that reason from externally supplied instances to produce general hypotheses, which then make predictions about future instances. In other words, the goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various supervised machine learning classification techniques. Of course, a single article cannot be a complete review of all supervised machine learning classification algorithms (also known induction classification algorithms), yet we hope that the references cited will cover the major theoretical issues, guiding the researcher in interesting research directions and suggesting possible bias combinations that have yet to be explored.},
	author = {Kotsiantis, S. B.},
	booktitle = {Informatica (Ljubljana)},
	issn = {03505596},
	keywords = {Classifiers,Data mining techniques,Intelligent data analysis,Learning algorithms},
	title = {{Supervised machine learning: A review of classification techniques}},
	year = {2007}
}

@Incollection{Wojtusiak2012,
	author= {Wojtusiak, Janusz},
	editor= {Seel, Norbert M.},
	title= {{Machine Learning}},
	bookTitle= {{Encyclopedia of the Sciences of Learning}},
	year = {2012},
	publisher= {Springer US},
	address = {Boston, MA},
	isbn = {978-1-4419-1428-6},
	doi = {10.1007/978-1-4419-1428-6_1927},
	url = {https://doi.org/10.1007/978-1-4419-1428-6_1927}
}

@article{Colby:1974,
	author = {Colby, Kenneth Mark},
	title = {Ten Criticisms of Parry},
	journal = {SIGART Bull.},
	issue_date = {1974},
	number = {48},
	month = {8},
	year = {1974},
	issn = {0163-5719},
	pages = {5--9},
	numpages = {5},
	url = {http://doi.acm.org/10.1145/1045200.1045202},
	doi = {10.1145/1045200.1045202},
	acmid = {1045202},
	publisher = {ACM},
	address = {New York, NY, USA}
}

@article{Colby:1981,
	author = {Colby, Kenneth},
	year = {1981},
	month = {12},
	pages = {515 - 534},
	title = {Modeling a Paranoid Mind},
	volume = {4},
	journal = {Behavioral and Brain Sciences},
	doi = {10.1017/S0140525X00000030}
}

@Online{Flask:online,
	author = {Flask},
	title = {{Official Flask Documentation}},
	url = {http://flask.pocoo.org/docs/1.0/},
	month = {},
	year = {2019},
	urldate = {2019-03-28}
}

@incollection{intel:online,
	title = {Intelligence},
	url = {https://en.oxforddictionaries.com/definition/intelligence},
	booktitle = {{Oxford English Dictionary Online}},
	publisher = {Oxford University Press},
	urldate = {2018-10-24},
	date = {n.d.}
}

@book{Goldberg2017,
	author = {Goldberg, Yoav and Hirst, Graeme},
	title = {Neural Network Methods in Natural Language Processing},
	year = {2017},
	isbn = {1627052984},
	publisher = {Morgan \& Claypool Publishers}
} 

@online{watson:online,
	author = {Adam Gabbatt},
	title = {{IBM computer Watson wins Jeopardy clash}},
	url = {https://www.theguardian.com/technology/2011/feb/17/ibm-computer-watson-wins-jeopardy},
	month = {2},
	year = {2011},
	urldate = {2018-12-11}
}

@book{Manning2008,
	author = {Manning, Christopher D. and Raghavan, Prabhakar and Sch\"{u}tze, Hinrich},
	title = {Introduction to Information Retrieval},
	year = {2008},
	isbn = {0521865719, 9780521865715},
	publisher = {Cambridge University Press},
	address = {New York, NY, USA},
} 

@incollection{Porter1997,
	author = {Porter, M. F.},
	chapter = {An Algorithm for Suffix Stripping},
	title = {Readings in Information Retrieval},
	editor = {Sparck Jones, Karen and Willett, Peter},
	year = {1997},
	isbn = {1-55860-454-5},
	pages = {313--316},
	numpages = {4},
	url = {http://dl.acm.org/citation.cfm?id=275537.275705},
	acmid = {275705},
	publisher = {Morgan Kaufmann Publishers Inc.},
	address = {San Francisco, CA, USA},
} 

@article{Lovins1968,
	title={Development of a stemming algorithm},
	author={Julie Beth Lovins},
	journal={Mech. Translat. \& Comp. Linguistics},
	year={1968},
	volume={11},
	pages={22-31}
}

@article{Paice1990,
	author = {Paice, Chris D.},
	title = {Another Stemmer},
	journal = {SIGIR Forum},
	issue_date = {Fall 1990},
	volume = {24},
	number = {3},
	month = nov,
	year = {1990},
	issn = {0163-5840},
	pages = {56--61},
	numpages = {6},
	url = {http://doi.acm.org/10.1145/101306.101310},
	doi = {10.1145/101306.101310},
	acmid = {101310},
	publisher = {ACM},
	address = {New York, NY, USA},
} 

@inproceedings{Yarowsky1995,
	author = {Yarowsky, David},
	title = {Unsupervised Word Sense Disambiguation Rivaling Supervised Methods},
	booktitle = {Proceedings of the 33rd Annual Meeting on Association for Computational Linguistics},
	series = {ACL '95},
	year = {1995},
	location = {Cambridge, Massachusetts},
	pages = {189--196},
	numpages = {8},
	url = {https://doi.org/10.3115/981658.981684},
	doi = {10.3115/981658.981684},
	acmid = {981684},
	publisher = {Association for Computational Linguistics},
	address = {Stroudsburg, PA, USA},
} 

@book{Kononenko2007,
	author = {Kononenko, Igor and Kukar, Matjaz},
	title = {Machine Learning and Data Mining: Introduction to Principles and Algorithms},
	year = {2007},
	isbn = {1904275214, 9781904275213},
	publisher = {Horwood Publishing Limited},
} 

@inproceedings{rish2001empirical,
	title={An empirical study of the naive Bayes classifier},
	author={Rish, Irina and others},
	booktitle={IJCAI 2001 workshop on empirical methods in artificial intelligence},
	volume={3},
	number={22},
	pages={41--46},
	year={2001}
}

@inproceedings{mccallum1998comparison,
	title={A comparison of event models for naive bayes text classification},
	author={McCallum, Andrew and Nigam, Kamal and others},
	booktitle={AAAI-98 workshop on learning for text categorization},
	volume={752},
	number={1},
	pages={41--48},
	year={1998},
	organization={Citeseer}
}

@article{Pereira2018,
	abstract = {{\textcopyright} 2018 ACM. This work introduces a set of quality attributes for chatbots. The selection is grounded on scholarly but also reputed blog references from 2016 and 2017. In addition, attributes should be amenable to be extracted (semi) automatically. On these premises, we consider four attributes: "support of a minimal set of common commands", "foresee language variations in both inputs and ouput", "human-assistance provision" and "timeliness". These attributes are worked out for the 100 most popular chatbots in Facebook Messager. The aim is to look for correlations between these attributes and chatbot popularity in terms of number of "likes". Results show that there is no significance correlation with any of the attributes. However, the experiment come up with two main insights. First, the lack of common communication paterns that would permit users to move their experiences and expectations from one chatbot to another. Second, the existence of many programming errors that reflect that bot programming is still a nascent area.},
	author = {Pereira, J. and D{\'{i}}az, O.},
	doi = {10.1145/3167132.3167362},
	isbn = {9781450351911},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {2144--2150},
	title = {{A quality analysis of facebook messenger's most popular chatbots}},
	volume = {Part F1378},
	year = {2018}
}

@misc{Cleverbot:online,
	author = {Carpenter, R.},
	title = {Cleverbot},
	url = {https://www.cleverbot.com/},
	month = {},
	year = {2019},
	urldate = {2019-03-12}
}
